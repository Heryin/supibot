{
  "defaultTemperature": 0.5,
  "defaultHistoryMode": "enabled",
  "globalInputLimit": 5000,
  "outputLimit": {
    "default": 50,
    "maximum": 100
  },
  "lengthLimitExceededMessage": {
    "history": "Maximum history length exceeded for this model! Shorten your query, or clear your history with \"$gpt history:clear\" instead.",
    "regular": "Maximum query length exceeded for this model! Shorten your query instead."
  },
  "userTokenLimits": {
    "regular": {
      "hourly": 400,
      "daily": 1600
    },
    "subscriber": {
      "hourly": 4000,
      "daily": 16000
    }
  },
  "models": {
    "curie": {
      "url": "text-curie-001",
      "type": "string",
      "default": false,
      "inputLimit": 2500,
      "outputLimit": {
        "default": 100,
        "maximum": 500
      },
      "usageDivisor": 1
    },
    "davinci": {
      "url": "text-davinci-001",
      "type": "string",
      "default": false,
      "inputLimit": 250,
      "outputLimit": {
        "default": 100,
        "maximum": 100
      },
      "usageDivisor": 0.1
    },
    "turbo": {
      "url": "gpt-3.5-turbo",
      "type": "messages",
      "default": true,
      "inputLimit": 1500,
      "outputLimit": {
        "default": 100,
        "maximum": 500
      },
      "usageDivisor": 1
    }
  }
}
